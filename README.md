# COMP20008 2021 Semester 1 Assignment 1
Name: Simon Keng-Jeng Wong StudentID: 995097

GitHub Repository Link: https://github.com/COMP20008/assignment-1-simon-kj-wong.git

EDIT: This repository is a clone of an original that was created in semester 1 of 2021

Part A consists of reading in a csv file and wrangling the data to efficiently summarise and highlight monthly statistics as opposed to daily statistics and quantities already present in the csv. Upon trimming and adding a new quantity into the data, it is saved in a new csv file labelled, "owid-covid-data-2020-monthly.csv", and the first 5 rows are printed to the terminal. From this new csv, two scatter plots are created, one using the number of new cases for the x-axis and the new quantity, the case fatality rate for the y-axis. The other scatter plot uses the same data plots except rescaling the x-axis using the natural log. These two scatter plots plot monthly data for these two quantities by location in the year 2020, which is differentiated by the colour of the plots. Finally a small report is written up outlining the data wrangling and data presenting aspects.

Part B consists of initially abstracting the document ID out of files within a folder, saving the file name alongside the document ID in a csv file labelled, 'partb1.csv'. Consequently, using regular expressions, a function was created that would transform these files into purely lower case alphabet, removing all number and special characters, replacing all upper case letter with their lower case counterparts and replacing all white space to a singular white space. The new string is then outputted into the terminal. A basic search function is then produced, using the function just mentioned, this search function would take the arguments proceeding the function call and search for those exact words within the folder of files, labelled "001.txt" through to "124.txt", printing the document ID, by virtue of the csv file created. An advanced search algorithm was then implemented that would stem all words placed into command line and search for these base words within the files, producing a similar output. Finally, using the advanced search algorithm, the documents were ranked using a cosine similarity score, represented as a Pandas DataFrame structure. Files with the highest similarity score were placed at the top with following files being placed in descending order.
